use anyhow::{anyhow, Result};
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::env;

use crate::models::Subtitle;

/// Sample subtitles evenly across the entire video for chapter generation
/// Returns a condensed representation that covers the whole video
fn sample_subtitles_for_chapters(subtitles: &[Subtitle], max_chars: usize) -> String {
    if subtitles.is_empty() {
        return String::new();
    }

    // Get total duration (use end time of last subtitle)
    let total_duration = subtitles.last().map(|s| s.end).unwrap_or(0.0);

    // For short videos (< 10 min), use all subtitles
    if total_duration < 600.0 {
        let text: String = subtitles
            .iter()
            .map(|s| format!("[{:.0}s] {}", s.start, s.text))
            .collect::<Vec<_>>()
            .join("\n");
        return text[..text.len().min(max_chars)].to_string();
    }

    // For longer videos, sample evenly
    // Aim for roughly 1 subtitle every 20-30 seconds
    let sample_interval = (total_duration / 200.0).max(20.0); // At least 200 samples or every 20s
    let mut sampled = Vec::new();
    let mut next_time = 0.0;

    for subtitle in subtitles {
        if subtitle.start >= next_time {
            sampled.push(format!("[{:.0}s] {}", subtitle.start, subtitle.text));
            next_time = subtitle.start + sample_interval;
        }
    }

    // Always include the last subtitle to show video end
    if let Some(last) = subtitles.last() {
        let last_entry = format!("[{:.0}s] {}", last.start, last.text);
        if !sampled.last().map(|s| s == &last_entry).unwrap_or(false) {
            sampled.push(last_entry);
        }
    }

    let result = sampled.join("\n");
    result[..result.len().min(max_chars)].to_string()
}

/// Vocabulary item extracted from subtitle
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VocabularyItem {
    pub word: String,
    pub meaning: String,
    pub level: String,  // "雅思", "四级", "六级", "托福", "日常"
    pub example: String,
}

/// Slide structure for presentation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Slide {
    pub slide_type: String, // "title", "content", "summary"
    pub title: String,
    pub subtitle: Option<String>,
    pub bullets: Vec<String>,
    pub notes: Option<String>, // Speaker notes
}

/// Chapter/section of a video for table of contents
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Chapter {
    pub title: String,
    pub start_time: f64, // Start time in seconds
}

/// Review question generated by AI
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReviewQuestion {
    pub vocab_id: i32,
    pub word: String,
    pub meaning: String,
    pub source_sentence: Option<String>,
    pub question_type: String, // "context", "meaning", "usage", "spelling"
    pub question: String,
}

/// Vocabulary info for generating review questions
#[derive(Debug, Clone)]
pub struct VocabForReview {
    pub id: i32,
    pub word: String,
    pub meaning: String,
    pub source_sentence: Option<String>,
}

/// AI evaluation of user's answer
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ReviewEvaluation {
    pub is_correct: bool,
    pub feedback: String,
    pub follow_up: Option<String>,
    pub quality: i32, // 0-3 for SM-2 algorithm
}

/// AI-generated memory card for vocabulary learning
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryCard {
    pub word: String,
    pub phonetic: Option<String>,
    pub part_of_speech: Option<String>,
    pub meaning: String,
    pub etymology: Option<String>,      // 词根词缀拆解
    pub mnemonic: Option<String>,       // 联想记忆法
    pub memory_story: Option<String>,   // 记忆故事
    pub example_sentence: Option<String>, // AI生成例句
    pub visual_hint: Option<String>,    // 视觉联想描述
}

/// AI Provider trait - implement this for each provider
#[async_trait]
pub trait AiProvider: Send + Sync {
    /// Analyze subtitles and return indices of important sentences
    async fn analyze_highlights(&self, subtitles: &[Subtitle]) -> Result<Vec<usize>>;

    /// Answer a question about the given context
    async fn ask_question(&self, context: &str, question: &str) -> Result<String>;

    /// Translate subtitles to Chinese
    async fn translate_subtitles(&self, subtitles: &[Subtitle]) -> Result<Vec<String>>;

    /// Extract important vocabulary from subtitle text
    async fn extract_vocabulary(&self, text: &str) -> Result<Vec<VocabularyItem>>;

    /// Generate a mind map markdown from video content
    async fn generate_mindmap(&self, title: &str, content: &str) -> Result<String>;

    /// Generate presentation slides from video content
    async fn generate_slides(&self, title: &str, content: &str) -> Result<Vec<Slide>>;

    /// Generate table of contents / chapters from subtitles
    async fn generate_chapters(&self, subtitles: &[Subtitle]) -> Result<Vec<Chapter>>;

    /// Generate review questions for vocabulary
    async fn generate_review_questions(&self, vocab_list: &[VocabForReview]) -> Result<Vec<ReviewQuestion>>;

    /// Generate a single review question for one vocabulary item
    async fn generate_single_review_question(&self, vocab: &VocabForReview, question_type: &str) -> Result<ReviewQuestion>;

    /// Evaluate user's answer to a review question
    async fn evaluate_review_answer(
        &self,
        word: &str,
        meaning: &str,
        question: &str,
        user_answer: &str,
    ) -> Result<ReviewEvaluation>;

    /// Generate AI memory card for vocabulary learning
    async fn generate_memory_card(
        &self,
        word: &str,
        meaning: &str,
        context: Option<&str>,
    ) -> Result<MemoryCard>;
}

/// Get the configured AI provider
pub fn get_ai_provider() -> Result<Box<dyn AiProvider>> {
    let provider = env::var("AI_PROVIDER").unwrap_or_else(|_| "gemini".to_string());

    match provider.to_lowercase().as_str() {
        "gemini" => {
            let api_key = env::var("GEMINI_API_KEY")
                .map_err(|_| anyhow!("GEMINI_API_KEY not set"))?;
            Ok(Box::new(GeminiProvider::new(api_key)))
        }
        "claude" => {
            let api_key = env::var("CLAUDE_API_KEY")
                .map_err(|_| anyhow!("CLAUDE_API_KEY not set"))?;
            Ok(Box::new(ClaudeProvider::new(api_key)))
        }
        "openai" => {
            let api_key = env::var("OPENAI_API_KEY")
                .map_err(|_| anyhow!("OPENAI_API_KEY not set"))?;
            Ok(Box::new(OpenAIProvider::new(api_key)))
        }
        _ => Err(anyhow!("Unknown AI provider: {}", provider)),
    }
}

// ============================================================================
// Gemini Provider
// ============================================================================

pub struct GeminiProvider {
    api_key: String,
    client: Client,
}

impl GeminiProvider {
    pub fn new(api_key: String) -> Self {
        Self {
            api_key,
            client: Client::new(),
        }
    }
}

#[derive(Serialize)]
struct GeminiRequest {
    contents: Vec<GeminiContent>,
    #[serde(rename = "generationConfig")]
    generation_config: GeminiGenerationConfig,
}

#[derive(Serialize)]
struct GeminiGenerationConfig {
    #[serde(rename = "maxOutputTokens")]
    max_output_tokens: u32,
}

#[derive(Serialize)]
struct GeminiContent {
    parts: Vec<GeminiPart>,
}

#[derive(Serialize)]
struct GeminiPart {
    text: String,
}

#[derive(Deserialize)]
struct GeminiResponse {
    candidates: Option<Vec<GeminiCandidate>>,
}

#[derive(Deserialize)]
struct GeminiCandidate {
    content: GeminiContentResponse,
}

#[derive(Deserialize)]
struct GeminiContentResponse {
    parts: Vec<GeminiPartResponse>,
}

#[derive(Deserialize)]
struct GeminiPartResponse {
    text: String,
}

#[async_trait]
impl AiProvider for GeminiProvider {
    async fn analyze_highlights(&self, subtitles: &[Subtitle]) -> Result<Vec<usize>> {
        let subtitle_text: String = subtitles
            .iter()
            .enumerate()
            .map(|(i, s)| format!("[{}] {}", i, s.text))
            .collect::<Vec<_>>()
            .join("\n");

        let prompt = format!(
            r#"Analyze these English subtitles from a video and identify the most important/educational sentences for English learners.

Subtitles:
{}

Return ONLY a JSON array of indices (numbers) for the 5-10 most important sentences.
Important sentences include: key phrases, idiomatic expressions, useful grammar patterns, or main points.

Example response: [0, 3, 7, 12, 15]

Response:"#,
            subtitle_text
        );

        let response = self.call_gemini(&prompt).await?;

        // Parse the response to extract indices
        let indices: Vec<usize> = serde_json::from_str(&response)
            .or_else(|_| {
                // Try to extract array from response
                let re = regex::Regex::new(r"\[[\d,\s]+\]").unwrap();
                if let Some(mat) = re.find(&response) {
                    serde_json::from_str(mat.as_str())
                } else {
                    Ok(vec![])
                }
            })
            .unwrap_or_default();

        Ok(indices)
    }

    async fn ask_question(&self, context: &str, question: &str) -> Result<String> {
        let prompt = format!(
            r#"你是一位英语学习助手。用户正在观看英语视频并提问。

当前字幕上下文:
"{}"

用户问题: {}

回答要求:
1. 如果问题与视频内容无关或是简单的闲聊（如"OK"、"好的"、"谢谢"），只需一句话简短回应
2. 只有当问题确实与视频内容或英语学习相关时，才详细解释
3. 回答要简洁，通常2-3句话足够，最多不超过100字
4. 解释词汇或语法时要结合视频上下文

用与问题相同的语言回答。"#,
            context, question
        );

        self.call_gemini(&prompt).await
    }

    async fn translate_subtitles(&self, subtitles: &[Subtitle]) -> Result<Vec<String>> {
        // Batch subtitles for efficient translation (max 20 per batch)
        let mut all_translations = Vec::new();

        for chunk in subtitles.chunks(20) {
            let texts: Vec<String> = chunk
                .iter()
                .enumerate()
                .map(|(i, s)| format!("[{}] {}", i, s.text))
                .collect();

            let prompt = format!(
                r#"Translate the following English subtitles to Chinese (Simplified).
Keep translations natural and conversational.
Return ONLY a JSON array of translated strings, in the same order.

Subtitles:
{}

Example response format: ["翻译1", "翻译2", "翻译3"]

Response (JSON array only):"#,
                texts.join("\n")
            );

            let response = self.call_gemini(&prompt).await?;

            // Parse JSON array from response
            let translations: Vec<String> = parse_translation_response(&response, chunk.len());

            all_translations.extend(translations);
        }

        // Ensure we have the right number of translations
        while all_translations.len() < subtitles.len() {
            all_translations.push(String::new());
        }
        all_translations.truncate(subtitles.len());

        Ok(all_translations)
    }

    async fn extract_vocabulary(&self, text: &str) -> Result<Vec<VocabularyItem>> {
        let prompt = format!(
            r#"从以下英文内容中提取重点词汇和常用短语。

内容: "{}"

提取要求:
1. 重点词汇：CET-4、CET-6、IELTS、TOEFL、GRE 核心词汇
2. 常用短语：实用的固定搭配、习语、口语表达（如 "figure out", "in terms of", "take advantage of"）
3. 不要提取简单词（如 the, is, a, have, do）
4. 每项提供：词性+中文释义、等级、实用例句
5. 等级标记：CET-4、CET-6、IELTS、TOEFL、GRE、Phrase（短语用 Phrase）
6. 去重：相同词汇只保留一个

返回JSON数组格式:
[
  {{"word": "leverage", "meaning": "(v.) 充分利用", "level": "CET-6", "example": "Let's leverage this opportunity."}},
  {{"word": "figure out", "meaning": "(phrase) 弄清楚，想出", "level": "Phrase", "example": "I need to figure out the problem."}},
  {{"word": "in terms of", "meaning": "(phrase) 就...而言", "level": "Phrase", "example": "In terms of cost, it's affordable."}}
]

只返回JSON数组，不要其他内容:"#,
            text
        );

        let response = self.call_gemini(&prompt).await?;

        // Parse JSON response
        let items: Vec<VocabularyItem> = parse_vocabulary_response(&response);
        Ok(items)
    }

    async fn generate_mindmap(&self, title: &str, content: &str) -> Result<String> {
        let prompt = format!(
            r#"基于以下视频内容，生成一个思维导图的 Markdown 格式。

视频标题: {}

视频字幕内容:
{}

要求:
1. 用 Markdown 标题格式表示层级关系（# 一级, ## 二级, ### 三级）
2. 提取3-5个主要主题作为二级标题
3. 每个主题下列出2-4个关键点作为三级标题
4. 关键点下可以用列表(-)补充具体内容
5. 内容要精炼，每个点不超过15个字
6. 用中文输出，但保留重要的英文术语

示例格式:
# 视频主题
## 主题一
### 关键点1
- 补充说明
### 关键点2
## 主题二
### 关键点1

请直接输出 Markdown 格式，不要其他解释:"#,
            title,
            &content[..content.len().min(8000)] // Limit content length
        );

        self.call_gemini(&prompt).await
    }

    async fn generate_slides(&self, title: &str, content: &str) -> Result<Vec<Slide>> {
        let prompt = format!(
            r#"Generate presentation slides based on video content to help users quickly understand and review the key points.

Video Title: {}

Content:
{}

## Requirements

1. Create 8-12 slides with rich content
2. Structure: Title slide + 6-10 content slides + Summary slide
3. Each slide should have 3-5 bullet points, each expressing a complete idea
4. Bullet points should be specific and informative, avoid vague statements
5. Write in English
6. Use notes field for key details or examples (1-2 sentences)

### JSON Format:
[
  {{"slide_type": "title", "title": "Main Title", "subtitle": "Speaker/Source", "bullets": [], "notes": null}},
  {{"slide_type": "content", "title": "Key Point Title", "subtitle": null, "bullets": ["Complete description of the point", "Another informative bullet"], "notes": "Additional details or examples"}},
  {{"slide_type": "summary", "title": "Key Takeaways", "subtitle": null, "bullets": ["Specific takeaway 1", "Specific takeaway 2"], "notes": null}}
]

Output JSON array only:"#,
            title,
            &content[..content.len().min(12000)]
        );

        let response = self.call_gemini(&prompt).await?;
        parse_slides_response(&response)
    }

    async fn generate_chapters(&self, subtitles: &[Subtitle]) -> Result<Vec<Chapter>> {
        // Sample subtitles evenly across the entire video
        let sampled_text = sample_subtitles_for_chapters(subtitles, 15000);

        // Get total duration for context
        let total_duration = subtitles.last().map(|s| s.end).unwrap_or(0.0);
        let duration_min = (total_duration / 60.0).ceil() as i32;

        let prompt = format!(
            r#"Analyze the following video subtitles and create a table of contents with 6-12 chapters.

Video duration: approximately {} minutes
Subtitles (sampled with timestamps in seconds):
{}

Requirements:
1. Create 6-12 main chapters covering the ENTIRE video
2. Each chapter should have a clear, concise title (in English, max 6 words)
3. Use the exact start_time (in seconds) where each topic begins
4. Chapters MUST be distributed across the full video duration (0 to ~{}s)
5. First chapter should start at 0
6. Last chapter should be in the final third of the video

Return ONLY a JSON array in this format:
[
  {{"title": "Introduction", "start_time": 0}},
  {{"title": "Main Topic One", "start_time": 120}},
  {{"title": "Key Concepts", "start_time": 300}},
  {{"title": "Final Thoughts", "start_time": 600}}
]

JSON array only:"#,
            duration_min,
            sampled_text,
            total_duration as i32
        );

        let response = self.call_gemini(&prompt).await?;
        parse_chapters_response(&response)
    }

    async fn generate_review_questions(&self, vocab_list: &[VocabForReview]) -> Result<Vec<ReviewQuestion>> {
        let mut questions = Vec::new();
        let question_types = ["meaning", "usage", "context", "spelling"];

        for (i, vocab) in vocab_list.iter().enumerate() {
            let question_type = question_types[i % question_types.len()];
            let context_hint = vocab.source_sentence.as_deref().unwrap_or("无语境");

            let prompt = format!(
                r#"你是一位友好的英语老师，正在帮学生复习单词。

单词: "{}"
中文含义: "{}"
原句语境: "{}"

请生成一个自然的复习问题。问题类型: {}
- meaning: 直接问这个词是什么意思
- usage: 让学生用这个词造一个句子
- context: 回顾语境，问学生是否记得这个词在原句中的意思
- spelling: 告诉学生你会播放发音，让他们拼写这个单词

要求:
1. 用中文提问
2. 语气友好轻松，像朋友聊天
3. 问题要简洁，不超过30字
4. 不要直接透露答案

只返回问题本身，不要其他内容:"#,
                vocab.word, vocab.meaning, context_hint, question_type
            );

            let question_text = self.call_gemini(&prompt).await.unwrap_or_else(|_| {
                match question_type {
                    "meaning" => format!("「{}」这个词是什么意思？", vocab.word),
                    "usage" => format!("用「{}」造一个句子吧！", vocab.word),
                    "context" => format!("还记得「{}」在视频里是什么意思吗？", vocab.word),
                    "spelling" => "听发音，把这个单词拼出来吧！".to_string(),
                    _ => format!("「{}」是什么意思？", vocab.word),
                }
            });

            questions.push(ReviewQuestion {
                vocab_id: vocab.id,
                word: vocab.word.clone(),
                meaning: vocab.meaning.clone(),
                source_sentence: vocab.source_sentence.clone(),
                question_type: question_type.to_string(),
                question: question_text.trim().to_string(),
            });
        }

        Ok(questions)
    }

    async fn generate_single_review_question(&self, vocab: &VocabForReview, question_type: &str) -> Result<ReviewQuestion> {
        let context_hint = vocab.source_sentence.as_deref().unwrap_or("无语境");

        let prompt = format!(
            r#"你是一位友好的英语老师，正在帮学生复习单词。

单词: "{}"
中文含义: "{}"
原句语境: "{}"

请生成一个自然的复习问题。问题类型: {}
- meaning: 直接问这个词是什么意思
- usage: 让学生用这个词造一个句子
- context: 回顾语境，问学生是否记得这个词在原句中的意思
- spelling: 告诉学生你会播放发音，让他们拼写这个单词

要求:
1. 用中文提问
2. 语气友好轻松，像朋友聊天
3. 问题要简洁，不超过30字
4. 不要直接透露答案

只返回问题本身，不要其他内容:"#,
            vocab.word, vocab.meaning, context_hint, question_type
        );

        let question_text = self.call_gemini(&prompt).await.unwrap_or_else(|_| {
            match question_type {
                "meaning" => format!("「{}」这个词是什么意思？", vocab.word),
                "usage" => format!("用「{}」造一个句子吧！", vocab.word),
                "context" => format!("还记得「{}」在视频里是什么意思吗？", vocab.word),
                "spelling" => "听发音，把这个单词拼出来吧！".to_string(),
                _ => format!("「{}」是什么意思？", vocab.word),
            }
        });

        Ok(ReviewQuestion {
            vocab_id: vocab.id,
            word: vocab.word.clone(),
            meaning: vocab.meaning.clone(),
            source_sentence: vocab.source_sentence.clone(),
            question_type: question_type.to_string(),
            question: question_text.trim().to_string(),
        })
    }

    async fn evaluate_review_answer(
        &self,
        word: &str,
        meaning: &str,
        question: &str,
        user_answer: &str,
    ) -> Result<ReviewEvaluation> {
        let prompt = format!(
            r#"你是一位友好的英语老师，正在批改学生的复习答案。

单词: "{}"
中文含义: "{}"
问题: "{}"
学生回答: "{}"

请评估学生的回答:
1. 判断是否正确（宽松判断，意思对或接近即可）
2. 给出简短友好的反馈（不超过20字）
3. 如果回答不太完整，可以给一个追问帮助学生加深理解（可选）
4. 给出质量分数: 0=完全不记得, 1=记得但很困难, 2=基本掌握, 3=非常熟练

返回JSON格式:
{{"is_correct": true/false, "feedback": "反馈内容", "follow_up": "追问内容或null", "quality": 0-3}}

只返回JSON，不要其他内容:"#,
            word, meaning, question, user_answer
        );

        let response = self.call_gemini(&prompt).await?;
        parse_review_evaluation(&response)
    }

    async fn generate_memory_card(
        &self,
        word: &str,
        meaning: &str,
        context: Option<&str>,
    ) -> Result<MemoryCard> {
        let context_text = context.unwrap_or("No specific context");

        let prompt = format!(
            r#"You are a vocabulary expert helping students understand English word origins and usage.

Word: "{}"
Meaning: "{}"
Context: "{}"

Generate a memory card with:

1. **Etymology**: Analyze word roots, prefixes, suffixes and explain the origin
   - Example: "insulin" = insula (Latin for "island") + -in → substance secreted by islets of Langerhans
   - If no clear roots, explain the word's historical evolution

2. **Real-life Example**: A sentence from everyday American life
   - Must be specific, realistic - like from American TV shows or daily conversations
   - Example: At the pharmacy, "I need to pick up my insulin prescription."

Return JSON format only:
{{
  "phonetic": "IPA phonetic transcription",
  "part_of_speech": "noun/verb/adj/adv/etc",
  "etymology": "Etymology explanation in English",
  "example_sentence": "Real-life example sentence in a specific American scenario"
}}

Return ONLY the JSON, nothing else:"#,
            word, meaning, context_text
        );

        let response = self.call_gemini(&prompt).await?;
        parse_memory_card_response(&response, word, meaning)
    }
}

impl GeminiProvider {
    async fn call_gemini(&self, prompt: &str) -> Result<String> {
        let url = format!(
            "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={}",
            self.api_key
        );

        let request = GeminiRequest {
            contents: vec![GeminiContent {
                parts: vec![GeminiPart {
                    text: prompt.to_string(),
                }],
            }],
            generation_config: GeminiGenerationConfig {
                max_output_tokens: 8192,
            },
        };

        let response = self
            .client
            .post(&url)
            .json(&request)
            .send()
            .await?
            .json::<GeminiResponse>()
            .await?;

        let text = response
            .candidates
            .and_then(|c| c.into_iter().next())
            .and_then(|c| c.content.parts.into_iter().next())
            .map(|p| p.text)
            .ok_or_else(|| anyhow!("No response from Gemini"))?;

        Ok(text)
    }
}

// ============================================================================
// Claude Provider (placeholder)
// ============================================================================

pub struct ClaudeProvider {
    api_key: String,
    client: Client,
}

impl ClaudeProvider {
    pub fn new(api_key: String) -> Self {
        Self {
            api_key,
            client: Client::new(),
        }
    }
}

#[async_trait]
impl AiProvider for ClaudeProvider {
    async fn analyze_highlights(&self, subtitles: &[Subtitle]) -> Result<Vec<usize>> {
        let subtitle_text: String = subtitles
            .iter()
            .enumerate()
            .map(|(i, s)| format!("[{}] {}", i, s.text))
            .collect::<Vec<_>>()
            .join("\n");

        let prompt = format!(
            r#"Analyze these English subtitles and identify 5-10 important sentences for English learners.
Return ONLY a JSON array of indices.

Subtitles:
{}

Response (JSON array only):"#,
            subtitle_text
        );

        let response = self.call_claude(&prompt).await?;

        let re = regex::Regex::new(r"\[[\d,\s]+\]").unwrap();
        let indices: Vec<usize> = re
            .find(&response)
            .and_then(|m| serde_json::from_str(m.as_str()).ok())
            .unwrap_or_default();

        Ok(indices)
    }

    async fn ask_question(&self, context: &str, question: &str) -> Result<String> {
        let prompt = format!(
            r#"你是一位英语学习助手。用户正在观看英语视频并提问。

当前字幕上下文:
"{}"

用户问题: {}

回答要求:
1. 如果问题与视频内容无关或是简单的闲聊（如"OK"、"好的"、"谢谢"），只需一句话简短回应
2. 只有当问题确实与视频内容或英语学习相关时，才详细解释
3. 回答要简洁，通常2-3句话足够，最多不超过100字
4. 解释词汇或语法时要结合视频上下文

用与问题相同的语言回答。"#,
            context, question
        );

        self.call_claude(&prompt).await
    }

    async fn translate_subtitles(&self, subtitles: &[Subtitle]) -> Result<Vec<String>> {
        let mut all_translations = Vec::new();

        for chunk in subtitles.chunks(20) {
            let texts: Vec<String> = chunk
                .iter()
                .enumerate()
                .map(|(i, s)| format!("[{}] {}", i, s.text))
                .collect();

            let prompt = format!(
                r#"Translate these English subtitles to Chinese (Simplified).
Return ONLY a JSON array of translated strings.

Subtitles:
{}

Response (JSON array only):"#,
                texts.join("\n")
            );

            let response = self.call_claude(&prompt).await?;
            let translations = parse_translation_response(&response, chunk.len());
            all_translations.extend(translations);
        }

        while all_translations.len() < subtitles.len() {
            all_translations.push(String::new());
        }
        all_translations.truncate(subtitles.len());

        Ok(all_translations)
    }

    async fn extract_vocabulary(&self, text: &str) -> Result<Vec<VocabularyItem>> {
        let prompt = format!(
            r#"Extract important vocabulary (IELTS, TOEFL, CET-4/6) from this sentence: "{}"
Return JSON array: [{{"word": "...", "meaning": "(v.) Chinese meaning", "level": "雅思/四级/六级/托福", "example": "Short daily example"}}]
Only return JSON array:"#,
            text
        );

        let response = self.call_claude(&prompt).await?;
        Ok(parse_vocabulary_response(&response))
    }

    async fn generate_mindmap(&self, title: &str, content: &str) -> Result<String> {
        let prompt = format!(
            r#"Generate a mind map in Markdown format for this video.
Title: {}
Content: {}

Use # for main topic, ## for themes (3-5), ### for key points (2-4 each).
Output in Chinese, keep important English terms. Be concise.
Output Markdown only:"#,
            title,
            &content[..content.len().min(8000)]
        );

        self.call_claude(&prompt).await
    }

    async fn generate_slides(&self, title: &str, content: &str) -> Result<Vec<Slide>> {
        let prompt = format!(
            r#"Generate presentation slides based on video content.

Title: {}
Content: {}

Requirements:
- Create 8-12 slides with rich content
- Structure: Title slide + 6-10 content slides + Summary slide
- Each slide: 3-5 bullet points, each expressing a complete idea
- Bullet points should be specific and informative
- Write in English
- Use notes field for key details or examples

Return JSON array:
[{{"slide_type": "title", "title": "Main Title", "subtitle": "Source", "bullets": [], "notes": null}},
{{"slide_type": "content", "title": "Key Point", "subtitle": null, "bullets": ["Complete description"], "notes": "Additional details"}},
{{"slide_type": "summary", "title": "Key Takeaways", "subtitle": null, "bullets": ["Specific takeaway"], "notes": null}}]"#,
            title,
            &content[..content.len().min(12000)]
        );

        let response = self.call_claude(&prompt).await?;
        parse_slides_response(&response)
    }

    async fn generate_chapters(&self, subtitles: &[Subtitle]) -> Result<Vec<Chapter>> {
        // Sample subtitles evenly across the entire video
        let sampled_text = sample_subtitles_for_chapters(subtitles, 12000);
        let total_duration = subtitles.last().map(|s| s.end).unwrap_or(0.0);
        let duration_min = (total_duration / 60.0).ceil() as i32;

        let prompt = format!(
            r#"Create 6-12 chapters for this ~{}min video covering the ENTIRE duration (0 to {}s).
Subtitles: {}
Return JSON array: [{{"title": "Chapter Name", "start_time": 0}}]"#,
            duration_min,
            total_duration as i32,
            sampled_text
        );

        let response = self.call_claude(&prompt).await?;
        parse_chapters_response(&response)
    }

    async fn generate_review_questions(&self, vocab_list: &[VocabForReview]) -> Result<Vec<ReviewQuestion>> {
        let mut questions = Vec::new();
        let question_types = ["meaning", "usage", "context", "spelling"];

        for (i, vocab) in vocab_list.iter().enumerate() {
            let question_type = question_types[i % question_types.len()];
            let context_hint = vocab.source_sentence.as_deref().unwrap_or("无语境");

            let prompt = format!(
                r#"生成一个复习问题。单词: "{}", 含义: "{}", 语境: "{}", 类型: {}
meaning=问含义, usage=造句, context=回顾语境, spelling=听写
用中文，友好简洁，不超过30字，不透露答案。只返回问题:"#,
                vocab.word, vocab.meaning, context_hint, question_type
            );

            let question_text = self.call_claude(&prompt).await.unwrap_or_else(|_| {
                format!("「{}」是什么意思？", vocab.word)
            });

            questions.push(ReviewQuestion {
                vocab_id: vocab.id,
                word: vocab.word.clone(),
                meaning: vocab.meaning.clone(),
                source_sentence: vocab.source_sentence.clone(),
                question_type: question_type.to_string(),
                question: question_text.trim().to_string(),
            });
        }

        Ok(questions)
    }

    async fn generate_single_review_question(&self, vocab: &VocabForReview, question_type: &str) -> Result<ReviewQuestion> {
        let context_hint = vocab.source_sentence.as_deref().unwrap_or("无语境");

        let prompt = format!(
            r#"生成一个复习问题。单词: "{}", 含义: "{}", 语境: "{}", 类型: {}
meaning=问含义, usage=造句, context=回顾语境, spelling=听写
用中文，友好简洁，不超过30字，不透露答案。只返回问题:"#,
            vocab.word, vocab.meaning, context_hint, question_type
        );

        let question_text = self.call_claude(&prompt).await.unwrap_or_else(|_| {
            format!("「{}」是什么意思？", vocab.word)
        });

        Ok(ReviewQuestion {
            vocab_id: vocab.id,
            word: vocab.word.clone(),
            meaning: vocab.meaning.clone(),
            source_sentence: vocab.source_sentence.clone(),
            question_type: question_type.to_string(),
            question: question_text.trim().to_string(),
        })
    }

    async fn evaluate_review_answer(
        &self,
        word: &str,
        meaning: &str,
        question: &str,
        user_answer: &str,
    ) -> Result<ReviewEvaluation> {
        let prompt = format!(
            r#"评估答案。单词:"{}" 含义:"{}" 问题:"{}" 回答:"{}"
返回JSON: {{"is_correct":bool,"feedback":"简短反馈","follow_up":null或追问,"quality":0-3}}"#,
            word, meaning, question, user_answer
        );

        let response = self.call_claude(&prompt).await?;
        parse_review_evaluation(&response)
    }

    async fn generate_memory_card(
        &self,
        word: &str,
        meaning: &str,
        context: Option<&str>,
    ) -> Result<MemoryCard> {
        let context_text = context.unwrap_or("No specific context");
        let prompt = format!(
            r#"Generate vocabulary memory card. Word:"{}" Meaning:"{}" Context:"{}"
Requirements: etymology (word roots analysis), real-life American example sentence
Return JSON:{{"phonetic":"IPA","part_of_speech":"pos","etymology":"word origin in English","example_sentence":"realistic American daily life sentence"}}"#,
            word, meaning, context_text
        );
        let response = self.call_claude(&prompt).await?;
        parse_memory_card_response(&response, word, meaning)
    }
}

impl ClaudeProvider {
    async fn call_claude(&self, prompt: &str) -> Result<String> {
        #[derive(Serialize)]
        struct ClaudeRequest {
            model: String,
            max_tokens: u32,
            messages: Vec<ClaudeMessage>,
        }

        #[derive(Serialize)]
        struct ClaudeMessage {
            role: String,
            content: String,
        }

        #[derive(Deserialize)]
        struct ClaudeResponse {
            content: Vec<ClaudeContent>,
        }

        #[derive(Deserialize)]
        struct ClaudeContent {
            text: String,
        }

        let request = ClaudeRequest {
            model: "claude-3-haiku-20240307".to_string(),
            max_tokens: 1024,
            messages: vec![ClaudeMessage {
                role: "user".to_string(),
                content: prompt.to_string(),
            }],
        };

        let response = self
            .client
            .post("https://api.anthropic.com/v1/messages")
            .header("x-api-key", &self.api_key)
            .header("anthropic-version", "2023-06-01")
            .header("content-type", "application/json")
            .json(&request)
            .send()
            .await?
            .json::<ClaudeResponse>()
            .await?;

        response
            .content
            .into_iter()
            .next()
            .map(|c| c.text)
            .ok_or_else(|| anyhow!("No response from Claude"))
    }
}

// ============================================================================
// OpenAI Provider (placeholder)
// ============================================================================

pub struct OpenAIProvider {
    api_key: String,
    client: Client,
}

impl OpenAIProvider {
    pub fn new(api_key: String) -> Self {
        Self {
            api_key,
            client: Client::new(),
        }
    }
}

#[async_trait]
impl AiProvider for OpenAIProvider {
    async fn analyze_highlights(&self, subtitles: &[Subtitle]) -> Result<Vec<usize>> {
        let subtitle_text: String = subtitles
            .iter()
            .enumerate()
            .map(|(i, s)| format!("[{}] {}", i, s.text))
            .collect::<Vec<_>>()
            .join("\n");

        let prompt = format!(
            r#"Analyze these English subtitles and identify 5-10 important sentences for English learners.
Return ONLY a JSON array of indices.

Subtitles:
{}

Response:"#,
            subtitle_text
        );

        let response = self.call_openai(&prompt).await?;

        let re = regex::Regex::new(r"\[[\d,\s]+\]").unwrap();
        let indices: Vec<usize> = re
            .find(&response)
            .and_then(|m| serde_json::from_str(m.as_str()).ok())
            .unwrap_or_default();

        Ok(indices)
    }

    async fn ask_question(&self, context: &str, question: &str) -> Result<String> {
        let prompt = format!(
            r#"你是一位英语学习助手。用户正在观看英语视频并提问。

当前字幕上下文:
"{}"

用户问题: {}

回答要求:
1. 如果问题与视频内容无关或是简单的闲聊（如"OK"、"好的"、"谢谢"），只需一句话简短回应
2. 只有当问题确实与视频内容或英语学习相关时，才详细解释
3. 回答要简洁，通常2-3句话足够，最多不超过100字
4. 解释词汇或语法时要结合视频上下文

用与问题相同的语言回答。"#,
            context, question
        );

        self.call_openai(&prompt).await
    }

    async fn translate_subtitles(&self, subtitles: &[Subtitle]) -> Result<Vec<String>> {
        let mut all_translations = Vec::new();

        for chunk in subtitles.chunks(20) {
            let texts: Vec<String> = chunk
                .iter()
                .enumerate()
                .map(|(i, s)| format!("[{}] {}", i, s.text))
                .collect();

            let prompt = format!(
                r#"Translate these English subtitles to Chinese (Simplified).
Return ONLY a JSON array of translated strings.

Subtitles:
{}

Response (JSON array only):"#,
                texts.join("\n")
            );

            let response = self.call_openai(&prompt).await?;
            let translations = parse_translation_response(&response, chunk.len());
            all_translations.extend(translations);
        }

        while all_translations.len() < subtitles.len() {
            all_translations.push(String::new());
        }
        all_translations.truncate(subtitles.len());

        Ok(all_translations)
    }

    async fn extract_vocabulary(&self, text: &str) -> Result<Vec<VocabularyItem>> {
        let prompt = format!(
            r#"Extract important vocabulary (IELTS, TOEFL, CET-4/6) from this sentence: "{}"
Return JSON array: [{{"word": "...", "meaning": "(v.) Chinese meaning", "level": "雅思/四级/六级/托福", "example": "Short daily example"}}]
Only return JSON array:"#,
            text
        );

        let response = self.call_openai(&prompt).await?;
        Ok(parse_vocabulary_response(&response))
    }

    async fn generate_mindmap(&self, title: &str, content: &str) -> Result<String> {
        let prompt = format!(
            r#"Generate a mind map in Markdown format for this video.
Title: {}
Content: {}

Use # for main topic, ## for themes (3-5), ### for key points (2-4 each).
Output in Chinese, keep important English terms. Be concise.
Output Markdown only:"#,
            title,
            &content[..content.len().min(8000)]
        );

        self.call_openai(&prompt).await
    }

    async fn generate_slides(&self, title: &str, content: &str) -> Result<Vec<Slide>> {
        let prompt = format!(
            r#"Generate presentation slides based on video content to help users quickly understand and review the key points.

Video Title: {}
Content: {}

Requirements:
- Create 8-12 slides with rich content
- Structure: Title slide + 6-10 content slides + Summary slide
- Each slide should have 3-5 bullet points, each expressing a complete idea
- Bullet points should be specific and informative, avoid vague statements
- Write in English
- Use notes field for key details or examples (1-2 sentences)

Return JSON array:
[{{"slide_type": "title", "title": "Main Title", "subtitle": "Speaker/Source", "bullets": [], "notes": null}},
{{"slide_type": "content", "title": "Key Point Title", "subtitle": null, "bullets": ["Complete description of the point"], "notes": "Additional details"}},
{{"slide_type": "summary", "title": "Key Takeaways", "subtitle": null, "bullets": ["Specific takeaway"], "notes": null}}]"#,
            title,
            &content[..content.len().min(12000)]
        );

        let response = self.call_openai(&prompt).await?;
        parse_slides_response(&response)
    }

    async fn generate_chapters(&self, subtitles: &[Subtitle]) -> Result<Vec<Chapter>> {
        // Sample subtitles evenly across the entire video
        let sampled_text = sample_subtitles_for_chapters(subtitles, 12000);
        let total_duration = subtitles.last().map(|s| s.end).unwrap_or(0.0);
        let duration_min = (total_duration / 60.0).ceil() as i32;

        let prompt = format!(
            r#"Create 6-12 chapters for this ~{}min video covering the ENTIRE duration (0 to {}s).
Subtitles: {}
Return JSON array: [{{"title": "Chapter Name", "start_time": 0}}]"#,
            duration_min,
            total_duration as i32,
            sampled_text
        );

        let response = self.call_openai(&prompt).await?;
        parse_chapters_response(&response)
    }

    async fn generate_review_questions(&self, vocab_list: &[VocabForReview]) -> Result<Vec<ReviewQuestion>> {
        let mut questions = Vec::new();
        let question_types = ["meaning", "usage", "context", "spelling"];

        for (i, vocab) in vocab_list.iter().enumerate() {
            let question_type = question_types[i % question_types.len()];
            let context_hint = vocab.source_sentence.as_deref().unwrap_or("无语境");

            let prompt = format!(
                r#"生成一个复习问题。单词: "{}", 含义: "{}", 语境: "{}", 类型: {}
meaning=问含义, usage=造句, context=回顾语境, spelling=听写
用中文，友好简洁，不超过30字，不透露答案。只返回问题:"#,
                vocab.word, vocab.meaning, context_hint, question_type
            );

            let question_text = self.call_openai(&prompt).await.unwrap_or_else(|_| {
                format!("「{}」是什么意思？", vocab.word)
            });

            questions.push(ReviewQuestion {
                vocab_id: vocab.id,
                word: vocab.word.clone(),
                meaning: vocab.meaning.clone(),
                source_sentence: vocab.source_sentence.clone(),
                question_type: question_type.to_string(),
                question: question_text.trim().to_string(),
            });
        }

        Ok(questions)
    }

    async fn generate_single_review_question(&self, vocab: &VocabForReview, question_type: &str) -> Result<ReviewQuestion> {
        let context_hint = vocab.source_sentence.as_deref().unwrap_or("无语境");

        let prompt = format!(
            r#"生成一个复习问题。单词: "{}", 含义: "{}", 语境: "{}", 类型: {}
meaning=问含义, usage=造句, context=回顾语境, spelling=听写
用中文，友好简洁，不超过30字，不透露答案。只返回问题:"#,
            vocab.word, vocab.meaning, context_hint, question_type
        );

        let question_text = self.call_openai(&prompt).await.unwrap_or_else(|_| {
            format!("「{}」是什么意思？", vocab.word)
        });

        Ok(ReviewQuestion {
            vocab_id: vocab.id,
            word: vocab.word.clone(),
            meaning: vocab.meaning.clone(),
            source_sentence: vocab.source_sentence.clone(),
            question_type: question_type.to_string(),
            question: question_text.trim().to_string(),
        })
    }

    async fn evaluate_review_answer(
        &self,
        word: &str,
        meaning: &str,
        question: &str,
        user_answer: &str,
    ) -> Result<ReviewEvaluation> {
        let prompt = format!(
            r#"评估答案。单词:"{}" 含义:"{}" 问题:"{}" 回答:"{}"
返回JSON: {{"is_correct":bool,"feedback":"简短反馈","follow_up":null或追问,"quality":0-3}}"#,
            word, meaning, question, user_answer
        );

        let response = self.call_openai(&prompt).await?;
        parse_review_evaluation(&response)
    }

    async fn generate_memory_card(
        &self,
        word: &str,
        meaning: &str,
        context: Option<&str>,
    ) -> Result<MemoryCard> {
        let context_text = context.unwrap_or("No specific context");
        let prompt = format!(
            r#"Generate vocabulary memory card. Word:"{}" Meaning:"{}" Context:"{}"
Requirements: etymology (word roots analysis), real-life American example sentence
Return JSON:{{"phonetic":"IPA","part_of_speech":"pos","etymology":"word origin in English","example_sentence":"realistic American daily life sentence"}}"#,
            word, meaning, context_text
        );
        let response = self.call_openai(&prompt).await?;
        parse_memory_card_response(&response, word, meaning)
    }
}

impl OpenAIProvider {
    async fn call_openai(&self, prompt: &str) -> Result<String> {
        #[derive(Serialize)]
        struct OpenAIRequest {
            model: String,
            messages: Vec<OpenAIMessage>,
        }

        #[derive(Serialize)]
        struct OpenAIMessage {
            role: String,
            content: String,
        }

        #[derive(Deserialize)]
        struct OpenAIResponse {
            choices: Vec<OpenAIChoice>,
        }

        #[derive(Deserialize)]
        struct OpenAIChoice {
            message: OpenAIMessageResponse,
        }

        #[derive(Deserialize)]
        struct OpenAIMessageResponse {
            content: String,
        }

        let request = OpenAIRequest {
            model: "gpt-3.5-turbo".to_string(),
            messages: vec![OpenAIMessage {
                role: "user".to_string(),
                content: prompt.to_string(),
            }],
        };

        let response = self
            .client
            .post("https://api.openai.com/v1/chat/completions")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .json(&request)
            .send()
            .await?
            .json::<OpenAIResponse>()
            .await?;

        response
            .choices
            .into_iter()
            .next()
            .map(|c| c.message.content)
            .ok_or_else(|| anyhow!("No response from OpenAI"))
    }
}

/// Helper function to parse translation response from AI
fn parse_translation_response(response: &str, expected_count: usize) -> Vec<String> {
    // Try to parse directly as JSON array
    if let Ok(translations) = serde_json::from_str::<Vec<String>>(response) {
        return translations;
    }

    // Clean up the response - remove markdown code blocks
    let cleaned = response
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim();

    // Try parsing cleaned response
    if let Ok(translations) = serde_json::from_str::<Vec<String>>(cleaned) {
        return translations;
    }

    // Try to extract JSON array using regex (multiline support)
    let re = regex::Regex::new(r"(?s)\[[\s\S]*\]").unwrap();
    if let Some(mat) = re.find(cleaned) {
        if let Ok(translations) = serde_json::from_str::<Vec<String>>(mat.as_str()) {
            return translations;
        }
    }

    // Log the failed response for debugging
    tracing::warn!("Failed to parse translation response: {}", &response[..response.len().min(200)]);

    // Return fallback (empty strings so UI won't show error text)
    vec![String::new(); expected_count]
}

/// Helper function to parse vocabulary response from AI
fn parse_vocabulary_response(response: &str) -> Vec<VocabularyItem> {
    // Try to parse directly as JSON array
    if let Ok(items) = serde_json::from_str::<Vec<VocabularyItem>>(response) {
        return items;
    }

    // Clean up the response - remove markdown code blocks
    let cleaned = response
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim();

    // Try parsing cleaned response
    if let Ok(items) = serde_json::from_str::<Vec<VocabularyItem>>(cleaned) {
        return items;
    }

    // Try to extract JSON array using regex (multiline support)
    let re = regex::Regex::new(r"(?s)\[[\s\S]*\]").unwrap();
    if let Some(mat) = re.find(cleaned) {
        if let Ok(items) = serde_json::from_str::<Vec<VocabularyItem>>(mat.as_str()) {
            return items;
        }
    }

    // Try to salvage partial data from truncated JSON
    // Find all complete JSON objects {...} and parse them individually
    let mut items = Vec::new();
    let obj_re = regex::Regex::new(r#"\{[^{}]*"word"\s*:\s*"[^"]+"\s*,[^{}]*\}"#).unwrap();
    for mat in obj_re.find_iter(cleaned) {
        if let Ok(item) = serde_json::from_str::<VocabularyItem>(mat.as_str()) {
            items.push(item);
        }
    }

    if !items.is_empty() {
        tracing::info!("Salvaged {} vocabulary items from truncated response", items.len());
        return items;
    }

    // Log the failed response for debugging (truncate at char boundary)
    let truncated = response.char_indices()
        .take_while(|(i, _)| *i < 200)
        .map(|(_, c)| c)
        .collect::<String>();
    tracing::warn!("Failed to parse vocabulary response: {}", truncated);

    // Return empty
    vec![]
}

/// Helper function to parse slides response from AI
fn parse_slides_response(response: &str) -> Result<Vec<Slide>> {
    // Try to parse directly as JSON array
    if let Ok(slides) = serde_json::from_str::<Vec<Slide>>(response) {
        return Ok(slides);
    }

    // Clean up the response - remove markdown code blocks
    let cleaned = response
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim();

    // Try parsing cleaned response
    if let Ok(slides) = serde_json::from_str::<Vec<Slide>>(cleaned) {
        return Ok(slides);
    }

    // Try to extract JSON array using regex (multiline support)
    let re = regex::Regex::new(r"(?s)\[[\s\S]*\]").unwrap();
    if let Some(mat) = re.find(cleaned) {
        if let Ok(slides) = serde_json::from_str::<Vec<Slide>>(mat.as_str()) {
            return Ok(slides);
        }
    }

    // Log the failed response for debugging
    tracing::warn!("Failed to parse slides response: {}", &response[..response.len().min(500)]);

    Err(anyhow!("Failed to parse slides from AI response"))
}

/// Helper function to parse chapters response from AI
fn parse_chapters_response(response: &str) -> Result<Vec<Chapter>> {
    // Try to parse directly as JSON array
    if let Ok(chapters) = serde_json::from_str::<Vec<Chapter>>(response) {
        return Ok(chapters);
    }

    // Clean up the response - remove markdown code blocks
    let cleaned = response
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim();

    // Try parsing cleaned response
    if let Ok(chapters) = serde_json::from_str::<Vec<Chapter>>(cleaned) {
        return Ok(chapters);
    }

    // Try to extract JSON array using regex (multiline support)
    let re = regex::Regex::new(r"(?s)\[[\s\S]*\]").unwrap();
    if let Some(mat) = re.find(cleaned) {
        if let Ok(chapters) = serde_json::from_str::<Vec<Chapter>>(mat.as_str()) {
            return Ok(chapters);
        }
    }

    // Log the failed response for debugging
    tracing::warn!("Failed to parse chapters response: {}", &response[..response.len().min(500)]);

    Err(anyhow!("Failed to parse chapters from AI response"))
}

/// Helper function to parse review evaluation response from AI
fn parse_review_evaluation(response: &str) -> Result<ReviewEvaluation> {
    // Try to parse directly as JSON
    if let Ok(eval) = serde_json::from_str::<ReviewEvaluation>(response) {
        return Ok(eval);
    }

    // Clean up the response - remove markdown code blocks
    let cleaned = response
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim();

    // Try parsing cleaned response
    if let Ok(eval) = serde_json::from_str::<ReviewEvaluation>(cleaned) {
        return Ok(eval);
    }

    // Try to extract JSON object using regex
    let re = regex::Regex::new(r"(?s)\{[\s\S]*\}").unwrap();
    if let Some(mat) = re.find(cleaned) {
        if let Ok(eval) = serde_json::from_str::<ReviewEvaluation>(mat.as_str()) {
            return Ok(eval);
        }
    }

    // Log the failed response for debugging
    tracing::warn!("Failed to parse review evaluation: {}", &response[..response.len().min(200)]);

    // Return a default evaluation if parsing fails
    Ok(ReviewEvaluation {
        is_correct: false,
        feedback: "我没能理解你的回答，请再试一次".to_string(),
        follow_up: None,
        quality: 1,
    })
}

/// Helper struct for parsing memory card JSON response
#[derive(Debug, Deserialize)]
struct MemoryCardResponse {
    phonetic: Option<String>,
    part_of_speech: Option<String>,
    etymology: Option<String>,
    mnemonic: Option<String>,
    memory_story: Option<String>,
    example_sentence: Option<String>,
    visual_hint: Option<String>,
}

/// Helper function to parse memory card response from AI
fn parse_memory_card_response(response: &str, word: &str, meaning: &str) -> Result<MemoryCard> {
    // Clean up the response - remove markdown code blocks
    let cleaned = response
        .trim()
        .trim_start_matches("```json")
        .trim_start_matches("```")
        .trim_end_matches("```")
        .trim();

    // Try to parse as JSON
    let parsed: Option<MemoryCardResponse> = serde_json::from_str(cleaned).ok().or_else(|| {
        // Try to extract JSON object using regex
        let re = regex::Regex::new(r"(?s)\{[\s\S]*\}").unwrap();
        re.find(cleaned)
            .and_then(|mat| serde_json::from_str(mat.as_str()).ok())
    });

    match parsed {
        Some(card) => Ok(MemoryCard {
            word: word.to_string(),
            phonetic: card.phonetic,
            part_of_speech: card.part_of_speech,
            meaning: meaning.to_string(),
            etymology: card.etymology,
            mnemonic: card.mnemonic,
            memory_story: card.memory_story,
            example_sentence: card.example_sentence,
            visual_hint: card.visual_hint,
        }),
        None => {
            tracing::warn!("Failed to parse memory card response: {}", &response[..response.len().min(300)]);
            // Return a basic card with just word and meaning
            Ok(MemoryCard {
                word: word.to_string(),
                phonetic: None,
                part_of_speech: None,
                meaning: meaning.to_string(),
                etymology: None,
                mnemonic: None,
                memory_story: None,
                example_sentence: None,
                visual_hint: None,
            })
        }
    }
}
